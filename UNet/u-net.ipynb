{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "\n",
    "import pathlib\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_layer(activation:str):\n",
    "\n",
    "    if activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_layer(normalization: str,\n",
    "                      num_channels: int, dim:int):\n",
    "    if dim == 2:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif dim == 3:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm3d(num_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer(pooling:str, dim:int):\n",
    "    if dim == 2:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        elif pooling == 'avg':\n",
    "            return nn.AvgPool2d(kernel_size=2,stride=2,padding=0)\n",
    "\n",
    "    if dim == 3:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool3d(kernel_size=2,stride=2,padding=0)\n",
    "        elif pooling == 'avg':\n",
    "            return nn.AvgPool3d(kernel_size=2,stride=2,padding=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_chs, out_chs, kernel_size, stride, padding, dim):\n",
    "    if dim == 2:\n",
    "        return nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\n",
    "    elif dim == 3:\n",
    "        return nn.Conv3d(in_chs, out_chs, kernel_size, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample_layer(up_sample,in_chs = None, out_chs = None, kernel_size = 2, stride = 2, dim = 3):\n",
    "    if up_sample == 'transposed':\n",
    "        if dim == 2:\n",
    "            return nn.ConvTranspose2d(in_chs, out_chs, kernel_size,stride)\n",
    "        elif dim == 3:\n",
    "            return nn.ConvTranspose3d(in_chs, out_chs, kernel_size,stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2, mode=up_sample) # mode can be 'nearest', 'bilinear' ,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cat(tensor1, tensor2):\n",
    "    \n",
    "    x = torch.cat((tensor1, tensor2), 1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add (tensor1, tensor2):\n",
    "    \n",
    "    x = torch.add(tensor1, tensor2)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    represent a block of left part of the U shape.\n",
    "    it contains two convolution layers, \n",
    "    each followed by a batch normalization (BN) and a leaky rectified,\n",
    "    and a downsampling layer followed by a BN and leakyRElu\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 stride_pooling:bool,\n",
    "                 pooling: str = \"max\",     \n",
    "                 kernel_size: int = 3,\n",
    "                 stride:int = 1,\n",
    "                 padding: int = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = 'BN',\n",
    "                 dim: int = 2\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.pooling = pooling\n",
    "        self.stride_pooling = stride_pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "        self.normalization_layer = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim)       \n",
    "        self.pooling_layer = pooling_layer(pooling = self.pooling, dim=self.dim)\n",
    "        self.stride_layer = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = 2, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        \n",
    "        #self.tensor_to_cat = nn.ModuleList()\n",
    "        self.conv_layer1 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        self.conv_layer2 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        connect_layer = x\n",
    "        if self.stride_pooling:\n",
    "            x = self.stride_layer(x)\n",
    "            \n",
    "        else:\n",
    "            x =  self.pooling_layer(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "                                                       \n",
    "        return x,connect_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(down_level, up_level):\n",
    "    \"\"\"\n",
    "    the input down_level is each level's last tensor on the left (down) side. e.g. [1,1,256,256,64]; up_level is the first\n",
    "    tensor on the right (up) side.\n",
    "    Center-crops the encoder_layer to the size of the decoder_layer,\n",
    "    so can catanate encoder layer to decoder layer\n",
    "    This is only necessary for input sizes != 2**n for 'same' padding and always required for 'valid' padding.\n",
    "    \"\"\"\n",
    "    if down_level.shape[2:] != up_level.shape[2:]:\n",
    "        down_shape = down_level.shape[2:]\n",
    "        up_shape = up_level.shape[2:]\n",
    "#down_shape should bigger than up_shape\n",
    "        if down_level.dim() == 4:  # 2D\n",
    "            down_level = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((down_shape[0] - up_shape[0]) // 2):((down_shape[0] + up_shape[0]) // 2),\n",
    "                            ((down_shape[1] - up_shape[1]) // 2):((down_shape[1] + up_shape[1]) // 2)\n",
    "                            ]\n",
    "        elif down_level.dim() == 5:  # 3D\n",
    "            down_level = down_level[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((down_shape[0] - up_shape[0]) // 2):((down_shape[0] + up_shape[0]) // 2),\n",
    "                            ((down_shape[1] - up_shape[1]) // 2):((down_shape[1] + up_shape[1]) // 2),\n",
    "                            ((down_shape[2] - up_shape[2]) // 2):((down_shape[2] + up_shape[2]) // 2),\n",
    "                            ]\n",
    "    return down_level, up_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    it corresponds to \"red arrow+blue arrow+ blue arrow\", i.e.\n",
    "    [decon_layer (half the number of channels)+ Upsampling (double image size)]+\n",
    "    [conv+bn+leaky]+[con+bn+leaky]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 concatenate:bool = False,\n",
    "                 add : bool = False,\n",
    "                 Crop:bool = False,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 3,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_ch =in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.concatenate = concatenate\n",
    "        self.add = add\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "\n",
    "    \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "     \n",
    "        self.up_sample_layer = up_sample_layer(up_sample = self.up_sample)\n",
    "        \n",
    "        self.conv_layer1 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        if self.add:\n",
    "            self.conv_layer2 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        elif self.concatenate:\n",
    "            self.conv_layer2 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "            self.conv_layer3 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        self.norm_layer = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim)        \n",
    "            \n",
    "    def forward(self, x, connect_layer):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        #deconv + upsample\n",
    "        x = self.conv_layer1(x) #128 -> 64\n",
    "        x = self.up_sample_layer(x) # 32*32 -> 64*64\n",
    "        \n",
    "        #merge\n",
    "        if self.concatenate:\n",
    "            x = Cat(connect_layer,x) #64 -> 128\n",
    "            x = self.conv_layer2(x) #128->64\n",
    "            x = self.norm_layer(x) \n",
    "            x = self.activation_layer(x)\n",
    "            x = self.conv_layer3(x) #64 -> 64\n",
    "            x = self.norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "            \n",
    "        elif self.add:\n",
    "            x = Add(connect_layer,x)\n",
    "        \n",
    "            #conv+bn+lrelu\n",
    "            x = self.conv_layer2(x)\n",
    "            x = self.norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "            #conv+bn+lrelu\n",
    "            x = self.conv_layer2(x)\n",
    "            x = self.norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "        \n",
    "        \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    it combines DownBlock + middle bottom of U shape + UpBlock + the final conv_layer.\n",
    "    we want to follow the UNet from the paper, so  here depth is 3, which means\n",
    "    the UNet will first run DownBlock for three times,\n",
    "    then reach the bottom, and will run \"conv+bn+leaky\" +\"conv+bn+leaky\",\n",
    "    then will run UpBlock for three times,\n",
    "    then we add the last layer to make channels from 16 -> 1\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 stride_pooling:bool,\n",
    "                 chs = [1,16,32,64,128],\n",
    "                 concatenate:bool = False,\n",
    "                 add:bool = False,\n",
    "                 Crop:bool=False,\n",
    "                 pooling = \"max\",\n",
    "                 \n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 3,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.chs = chs\n",
    "        self.depth = len(chs)-2\n",
    "        self.pooling = pooling\n",
    "        self.stride_pooling = stride_pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        self.concatenate = concatenate\n",
    "        self.add = add\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "        \n",
    "        self.encoder = nn.ModuleList([])\n",
    "        self.decoder = nn.ModuleList([])\n",
    "        for i in range(self.depth):\n",
    "            encoder_layer = DownBlock(\n",
    "                 in_ch=self.chs[i],\n",
    "                 out_ch=self.chs[i+1],\n",
    "                 #concatenate = True,\n",
    "                 stride_pooling = self.stride_pooling,\n",
    "                 pooling = self.pooling,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation = self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim= self.dim)\n",
    "            \n",
    "            self.encoder.append(encoder_layer)\n",
    "            \n",
    "            decoder_layer = UpBlock(\n",
    "                 in_ch = self.chs[-1-i],\n",
    "                 out_ch = self.chs[-2-i],\n",
    "                 concatenate= self.concatenate,\n",
    "                 add = self.add,\n",
    "                 Crop=self.Crop,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation= self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim = self.dim,\n",
    "                 up_sample= self.up_sample) \n",
    "            \n",
    "            self.decoder.append(decoder_layer)\n",
    "            \n",
    "        self.set_weights()\n",
    "        \n",
    "\n",
    "    @staticmethod        \n",
    "    def weight_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            #nn.init.xavier_normal(m.weight)\n",
    "            nn.init.constant(m.bias, 0)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('Sigmoid') != -1:\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "        #elif classname.find('Leaky') != -1:\n",
    "            #nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        elif classname.find('Linear') != -1:\n",
    "            nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            \n",
    "   \n",
    "    def set_weights(self):\n",
    "        for i,m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "            \n",
    "        \n",
    "    def forward(self,x):\n",
    "        connect_list = [] #it contains the layer from encoder path which need to skip to connect\n",
    "        \n",
    "        #encoder path\n",
    "        for i in range(self.depth):\n",
    "            block = self.encoder[i]\n",
    "            x,connect_layer = block(x)\n",
    "            connect_list.append(connect_layer)\n",
    "            \n",
    "        #bottom block: the middle and bottom part of UNet\n",
    "        \n",
    "        act_layer = activation_layer(self.activation)\n",
    "        conv_layer1 = conv_layer(self.chs[-2], self.chs[-1], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)          \n",
    "        conv_layer2 = conv_layer(self.chs[-1], self.chs[-1], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        norm_layer = normalization_layer(normalization=self.normalization, num_channels=self.chs[-1],\n",
    "                                           dim=self.dim)  \n",
    "        x = conv_layer1(x)\n",
    "        x = norm_layer(x)\n",
    "        x = act_layer(x)\n",
    "        x = conv_layer2(x)\n",
    "        x = norm_layer(x)\n",
    "        x = act_layer(x)\n",
    "        \n",
    "        #decoder path\n",
    "        for i in range(self.depth):\n",
    "            layer_to_connect = connect_list[-1-i]\n",
    "            block = self.decoder[i]\n",
    "            x = block(x,layer_to_connect)\n",
    "            \n",
    "        #last layer : 16 to 1\n",
    "        \n",
    "        \n",
    "        conv_layer_final = conv_layer(self.chs[1], self.chs[0], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        norm_layer_final = normalization_layer(normalization=self.normalization, num_channels=self.chs[0],\n",
    "                                           dim=self.dim) \n",
    "        x = conv_layer_final(x)\n",
    "        x = norm_layer_final(x)\n",
    "        x = act_layer(x)\n",
    "        #x = nn.Sigmoid()(x)\n",
    "        #x = nn.Linear(256,256)(x)\n",
    "            \n",
    "        return x\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:83: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    }
   ],
   "source": [
    "model_unet = UNet(chs = [1,16,32,64,128],\n",
    "                 concatenate= False, \n",
    "                 add = True,\n",
    "                 Crop=False,\n",
    "                 pooling = \"max\",\n",
    "                 stride_pooling = True, #if stride_pooling = True, than up_sample method will be conv_layer (stride=2)\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                  \n",
    "                 activation= 'leaky',\n",
    "                 normalization = \"BN\",\n",
    "                 dim= 2,\n",
    "                 up_sample = 'nearest').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 16, 256, 256]             160\n",
      "       BatchNorm2d-2          [1, 16, 256, 256]              32\n",
      "         LeakyReLU-3          [1, 16, 256, 256]               0\n",
      "            Conv2d-4          [1, 16, 256, 256]           2,320\n",
      "       BatchNorm2d-5          [1, 16, 256, 256]              32\n",
      "         LeakyReLU-6          [1, 16, 256, 256]               0\n",
      "            Conv2d-7          [1, 16, 128, 128]           2,320\n",
      "       BatchNorm2d-8          [1, 16, 128, 128]              32\n",
      "         LeakyReLU-9          [1, 16, 128, 128]               0\n",
      "        DownBlock-10  [[-1, 16, 128, 128], [-1, 16, 256, 256]]               0\n",
      "           Conv2d-11          [1, 32, 128, 128]           4,640\n",
      "      BatchNorm2d-12          [1, 32, 128, 128]              64\n",
      "        LeakyReLU-13          [1, 32, 128, 128]               0\n",
      "           Conv2d-14          [1, 32, 128, 128]           9,248\n",
      "      BatchNorm2d-15          [1, 32, 128, 128]              64\n",
      "        LeakyReLU-16          [1, 32, 128, 128]               0\n",
      "           Conv2d-17            [1, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-18            [1, 32, 64, 64]              64\n",
      "        LeakyReLU-19            [1, 32, 64, 64]               0\n",
      "        DownBlock-20  [[-1, 32, 64, 64], [-1, 32, 128, 128]]               0\n",
      "           Conv2d-21            [1, 64, 64, 64]          18,496\n",
      "      BatchNorm2d-22            [1, 64, 64, 64]             128\n",
      "        LeakyReLU-23            [1, 64, 64, 64]               0\n",
      "           Conv2d-24            [1, 64, 64, 64]          36,928\n",
      "      BatchNorm2d-25            [1, 64, 64, 64]             128\n",
      "        LeakyReLU-26            [1, 64, 64, 64]               0\n",
      "           Conv2d-27            [1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-28            [1, 64, 32, 32]             128\n",
      "        LeakyReLU-29            [1, 64, 32, 32]               0\n",
      "        DownBlock-30  [[-1, 64, 32, 32], [-1, 64, 64, 64]]               0\n",
      "           Conv2d-31            [1, 64, 32, 32]          73,792\n",
      "         Upsample-32            [1, 64, 64, 64]               0\n",
      "           Conv2d-33            [1, 64, 64, 64]          73,792\n",
      "      BatchNorm2d-34            [1, 64, 64, 64]             128\n",
      "        LeakyReLU-35            [1, 64, 64, 64]               0\n",
      "           Conv2d-36            [1, 64, 64, 64]          36,928\n",
      "      BatchNorm2d-37            [1, 64, 64, 64]             128\n",
      "        LeakyReLU-38            [1, 64, 64, 64]               0\n",
      "          UpBlock-39            [1, 64, 64, 64]               0\n",
      "           Conv2d-40            [1, 32, 64, 64]          18,464\n",
      "         Upsample-41          [1, 32, 128, 128]               0\n",
      "           Conv2d-42          [1, 32, 128, 128]          18,464\n",
      "      BatchNorm2d-43          [1, 32, 128, 128]              64\n",
      "        LeakyReLU-44          [1, 32, 128, 128]               0\n",
      "           Conv2d-45          [1, 32, 128, 128]           9,248\n",
      "      BatchNorm2d-46          [1, 32, 128, 128]              64\n",
      "        LeakyReLU-47          [1, 32, 128, 128]               0\n",
      "          UpBlock-48          [1, 32, 128, 128]               0\n",
      "           Conv2d-49          [1, 16, 128, 128]           4,624\n",
      "         Upsample-50          [1, 16, 256, 256]               0\n",
      "           Conv2d-51          [1, 16, 256, 256]           4,624\n",
      "      BatchNorm2d-52          [1, 16, 256, 256]              32\n",
      "        LeakyReLU-53          [1, 16, 256, 256]               0\n",
      "           Conv2d-54          [1, 16, 256, 256]           2,320\n",
      "      BatchNorm2d-55          [1, 16, 256, 256]              32\n",
      "        LeakyReLU-56          [1, 16, 256, 256]               0\n",
      "          UpBlock-57          [1, 16, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 363,664\n",
      "Trainable params: 363,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 210.00\n",
      "Params size (MB): 1.39\n",
      "Estimated Total Size (MB): 211.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_unet, (1,256,256), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_unet, \"UNet.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet = torch.load(\"UNet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload image and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "P = loadmat('xcat.mat')\n",
    "p = P['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p[:,:,120,2] #this give the chest image at time 2\n",
    "#P1= torch.from_numpy(p1)\n",
    "#P1 = P1.unsqueeze(0)\n",
    "#P1 = P1.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    " #0-1, numpy to tensor\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,\n",
    "                        0.5) # 0-1 to -1,1 and normalized\n",
    "])\n",
    "p2 = (p1-p1.min())/(p1.max()-p1.min())# scale to (0,1)\n",
    "p2 = transformer(p2)#scale to (-1,1)\n",
    "P = p2.unsqueeze(0)\n",
    "noise = np.clip(np.random.normal(scale=50, size=(256,256)), 0, 1).astype(np.float32) #scale to (0,1)\n",
    "noise_tensor = transformer(noise) #(-1,1)\n",
    "noise = noise_tensor.unsqueeze(0)\n",
    "\n",
    "#poisson_noise = torch.poisson(P1)*0.01\n",
    "#image = P+poisson_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a54032ac48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(P[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(optimizer:str = 'Adam'):\n",
    "    if optimizer == 'Adam':\n",
    "        return Adam(model.parameters(), lr=1e-4)\n",
    "    elif optimizer == 'SGD':\n",
    "        return torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(criterion:str = 'MSE'):\n",
    "    if criterion == 'MSE':\n",
    "        return nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(model,criterion_name,optimizer_name,input_image,label_image,epoch):\n",
    "    optimizer = optim(optimizer_name)\n",
    "    criterion = loss(criterion_name)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    def train(epoch):\n",
    "    #strat TRAIN mode\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        x_train, label= Variable(input_image), Variable(label_image)\n",
    "    \n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "        \n",
    "            x_train = x_train.cuda()           \n",
    "            label = label.cuda()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train)\n",
    "        output_img = output.detach().numpy()\n",
    "        \n",
    "        loss = criterion(output,label)\n",
    "    #compute gradient\n",
    "        loss.backward()\n",
    "    #update parameters\n",
    "        optimizer.step()    \n",
    "         \n",
    "    \n",
    "        train_loss = loss.item()\n",
    "        loss_list.append(train_loss)\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "        \n",
    "        \n",
    "        if (epoch+1) %200 == 0:  #this only display the output of tevery 200 iteration\n",
    "            fig.add_subplot(1,4,(epoch+1)/200)\n",
    "            plt.imshow(output_img[0,0,:,:])\n",
    "            plt.clim(0,1)\n",
    "    \n",
    "    return train(epoch)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_unet\n",
    "criterion_name = 'MSE'\n",
    "optimizer_name = 'Adam'\n",
    "#input_image = P1+ poisson_noise\n",
    "\n",
    "input_image = noise\n",
    "label_image = P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a540548d88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(P[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 1.194863\n",
      "Epoch: 1 \tTraining Loss: 1.951431\n",
      "Epoch: 2 \tTraining Loss: 1.951474\n",
      "Epoch: 3 \tTraining Loss: 1.355295\n",
      "Epoch: 4 \tTraining Loss: 1.216492\n",
      "Epoch: 5 \tTraining Loss: 1.945489\n",
      "Epoch: 6 \tTraining Loss: 1.821905\n",
      "Epoch: 7 \tTraining Loss: 1.950402\n",
      "Epoch: 8 \tTraining Loss: 1.031356\n",
      "Epoch: 9 \tTraining Loss: 1.254224\n",
      "Epoch: 10 \tTraining Loss: 1.951046\n",
      "Epoch: 11 \tTraining Loss: 1.031064\n",
      "Epoch: 12 \tTraining Loss: 1.764852\n",
      "Epoch: 13 \tTraining Loss: 1.943645\n",
      "Epoch: 14 \tTraining Loss: 1.941011\n",
      "Epoch: 15 \tTraining Loss: 1.880738\n",
      "Epoch: 16 \tTraining Loss: 1.023860\n",
      "Epoch: 17 \tTraining Loss: 1.026739\n",
      "Epoch: 18 \tTraining Loss: 1.216439\n",
      "Epoch: 19 \tTraining Loss: 1.949537\n",
      "Epoch: 20 \tTraining Loss: 1.022939\n",
      "Epoch: 21 \tTraining Loss: 1.953873\n",
      "Epoch: 22 \tTraining Loss: 1.931809\n",
      "Epoch: 23 \tTraining Loss: 1.949001\n",
      "Epoch: 24 \tTraining Loss: 1.032478\n",
      "Epoch: 25 \tTraining Loss: 1.948185\n",
      "Epoch: 26 \tTraining Loss: 1.036605\n",
      "Epoch: 27 \tTraining Loss: 1.335736\n",
      "Epoch: 28 \tTraining Loss: 1.346053\n",
      "Epoch: 29 \tTraining Loss: 1.506383\n",
      "Epoch: 30 \tTraining Loss: 1.029066\n",
      "Epoch: 31 \tTraining Loss: 1.034724\n",
      "Epoch: 32 \tTraining Loss: 1.947631\n",
      "Epoch: 33 \tTraining Loss: 1.021545\n",
      "Epoch: 34 \tTraining Loss: 1.025664\n",
      "Epoch: 35 \tTraining Loss: 1.061010\n",
      "Epoch: 36 \tTraining Loss: 1.916972\n",
      "Epoch: 37 \tTraining Loss: 1.839942\n",
      "Epoch: 38 \tTraining Loss: 1.021584\n",
      "Epoch: 39 \tTraining Loss: 1.946363\n",
      "Epoch: 40 \tTraining Loss: 1.195950\n",
      "Epoch: 41 \tTraining Loss: 1.950624\n",
      "Epoch: 42 \tTraining Loss: 1.066662\n",
      "Epoch: 43 \tTraining Loss: 1.596100\n",
      "Epoch: 44 \tTraining Loss: 1.025112\n",
      "Epoch: 45 \tTraining Loss: 1.024832\n",
      "Epoch: 46 \tTraining Loss: 1.947622\n",
      "Epoch: 47 \tTraining Loss: 1.948152\n",
      "Epoch: 48 \tTraining Loss: 1.028973\n",
      "Epoch: 49 \tTraining Loss: 1.028379\n",
      "Epoch: 50 \tTraining Loss: 1.032791\n",
      "Epoch: 51 \tTraining Loss: 1.940075\n",
      "Epoch: 52 \tTraining Loss: 1.017314\n",
      "Epoch: 53 \tTraining Loss: 1.015587\n",
      "Epoch: 54 \tTraining Loss: 1.016574\n",
      "Epoch: 55 \tTraining Loss: 1.168926\n",
      "Epoch: 56 \tTraining Loss: 1.022325\n",
      "Epoch: 57 \tTraining Loss: 1.034220\n",
      "Epoch: 58 \tTraining Loss: 1.916263\n",
      "Epoch: 59 \tTraining Loss: 1.946970\n",
      "Epoch: 60 \tTraining Loss: 1.064311\n",
      "Epoch: 61 \tTraining Loss: 1.020541\n",
      "Epoch: 62 \tTraining Loss: 1.919650\n",
      "Epoch: 63 \tTraining Loss: 1.807606\n",
      "Epoch: 64 \tTraining Loss: 1.948723\n",
      "Epoch: 65 \tTraining Loss: 1.056270\n",
      "Epoch: 66 \tTraining Loss: 1.949364\n",
      "Epoch: 67 \tTraining Loss: 1.247315\n",
      "Epoch: 68 \tTraining Loss: 1.925232\n",
      "Epoch: 69 \tTraining Loss: 1.911901\n",
      "Epoch: 70 \tTraining Loss: 1.606016\n",
      "Epoch: 71 \tTraining Loss: 1.766859\n",
      "Epoch: 72 \tTraining Loss: 1.742696\n",
      "Epoch: 73 \tTraining Loss: 1.016966\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 800\n",
    "train_loss = 0\n",
    "loss_list = []\n",
    "#rows = math.ceil(num_epochs/4)\n",
    "#fig = plt.figure(figsize=(rows*3,4*3))\n",
    "fig = plt.figure(figsize=(3,12))\n",
    "\n",
    "#fig.tight_layout()\n",
    "#plt.subplots_adjust(wspace =0, hspace =0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_setup(model,criterion_name,optimizer_name,input_image,label_image,epoch)\n",
    "    #plt.imshow(output_img[0,0,:,:])\n",
    "    #ax.set_title(classes[train_labels[idx]])\n",
    "    #train1(epoch)\n",
    "#draw loss plot\n",
    "#plt.plot(loss_list,label='Training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list,label='Training loss')\n",
    "\n",
    "plt.ylim((0.5,2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the following are simplified training process, keep it here in case need in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "def train1(epoch):\n",
    "    #strat TRAIN mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    x_train, label= Variable(input_image), Variable(label_image)\n",
    "    \n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        \n",
    "        x_train = x_train.cuda()           \n",
    "        label = label.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()    \n",
    "    \n",
    "    output = model(x_train)\n",
    "    output_img = output.detach().numpy()\n",
    "    \n",
    "        \n",
    "    loss = criterion(output,label)\n",
    "    #compute gradient\n",
    "    loss.backward()\n",
    "    #update parameters\n",
    "    optimizer.step()    \n",
    "\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    loss_list.append(train_loss)\n",
    "        \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "        \n",
    "        #fig.add_subplot(rows,4,epoch+1)\n",
    "        #plt.imshow(output_img[0,0,:,:])\n",
    "        #plt.clim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range (num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_image)\n",
    "    loss = criterion(output,label_image)\n",
    "    train_loss = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "        \n",
    "        #fig.add_subplot(rows,4,epoch+1)\n",
    "        #plt.imshow(output_img[0,0,:,:])\n",
    "        #plt.clim(0,1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
