{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_layer(activation:str):\n",
    "\n",
    "    if activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_layer(normalization: str,\n",
    "                      num_channels: int, dim:int):\n",
    "    if dim == 2:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif dim == 3:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm3d(num_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer(pooling:str, dim:int):\n",
    "    if dim == 2:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        #if pooling == 'stride':\n",
    "           # return nn.Conv2d()\n",
    "    if dim == 3:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool3d(kernel_size=2,stride=2,padding=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_chs, out_chs, kernel_size, stride, padding, dim):\n",
    "    if dim == 2:\n",
    "        return nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\n",
    "    elif dim == 3:\n",
    "        return nn.Conv3d(in_chs, out_chs, kernel_size, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample_layer(up_sample,in_chs = None, out_chs = None, kernel_size = 2, stride = 2, dim = 3):\n",
    "    if up_sample == 'transposed':\n",
    "        if dim == 2:\n",
    "            return nn.ConvTranspose2d(in_chs, out_chs, kernel_size,stride)\n",
    "        elif dim == 3:\n",
    "            return nn.ConvTranspose3d(in_chs, out_chs, kernel_size,stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2, mode=up_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cat(tensor1, tensor2):\n",
    "    \n",
    "    x = torch.cat((tensor1, tensor2), 1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add (tensor1, tensor2):\n",
    "    \n",
    "    x = torch.add(tensor1, tensor2)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    represent a block of left part of the U shape.\n",
    "    it contains two convolution layers, \n",
    "    each followed by a batch normalization (BN) and a leaky rectified,\n",
    "    and a downsampling layer followed by a BN and leakyRElu\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 pooling: str = \"max\",\n",
    "                 stride_pooling = True,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride:int = 1,\n",
    "                 padding: int = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = 'BN',\n",
    "                 dim: int = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.pooling = pooling\n",
    "        self.stride_pooling = stride_pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "        self.normalization_layer = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim)       \n",
    "        self.pooling_layer = pooling_layer(pooling = self.pooling, dim=self.dim)\n",
    "        self.stride_layer = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = 2, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        \n",
    "        #self.tensor_to_cat = nn.ModuleList()\n",
    "        self.conv_layer1 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        self.conv_layer2 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        connect_layer = x\n",
    "        if self.stride_pooling:\n",
    "            x = self.stride_layer(x)\n",
    "            \n",
    "        else:\n",
    "            x =  self.pooling_layer(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "                                                       \n",
    "        return x,connect_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(down_level, up_level):\n",
    "    \"\"\"\n",
    "    the input down_level is each level's last tensor on the left (down) side. e.g. [1,1,256,256,64]; up_level is the first\n",
    "    tensor on the right (up) side.\n",
    "    Center-crops the encoder_layer to the size of the decoder_layer,\n",
    "    so can catanate encoder layer to decoder layer\n",
    "    This is only necessary for input sizes != 2**n for 'same' padding and always required for 'valid' padding.\n",
    "    \"\"\"\n",
    "    if down_level.shape[2:] != up_level.shape[2:]:\n",
    "        down_shape = down_level.shape[2:]\n",
    "        up_shape = up_level.shape[2:]\n",
    "#down_shape should bigger than up_shape\n",
    "        if down_level.dim() == 4:  # 2D\n",
    "            down_level = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((down_shape[0] - up_shape[0]) // 2):((down_shape[0] + up_shape[0]) // 2),\n",
    "                            ((down_shape[1] - up_shape[1]) // 2):((down_shape[1] + up_shape[1]) // 2)\n",
    "                            ]\n",
    "        elif down_level.dim() == 5:  # 3D\n",
    "            down_level = down_level[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((down_shape[0] - up_shape[0]) // 2):((down_shape[0] + up_shape[0]) // 2),\n",
    "                            ((down_shape[1] - up_shape[1]) // 2):((down_shape[1] + up_shape[1]) // 2),\n",
    "                            ((down_shape[2] - up_shape[2]) // 2):((down_shape[2] + up_shape[2]) // 2),\n",
    "                            ]\n",
    "    return down_level, up_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 concatenate:bool = False,\n",
    "                 add : bool = False,\n",
    "                 Crop:bool = False,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 3,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_ch =in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.concatenate = concatenate\n",
    "        self.add = add\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "\n",
    "    \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "     \n",
    "        self.up_sample_layer = up_sample_layer(up_sample = self.up_sample)\n",
    "        \n",
    "        self.conv_layer1 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        if self.add:\n",
    "            self.conv_layer2 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        elif self.concatenate:\n",
    "            self.conv_layer2 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)            \n",
    "        self.norm_layer = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim)        \n",
    "            \n",
    "    def forward(self, x, connect_layer):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        #deconv + upsample\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.up_sample_layer(x)\n",
    "        \n",
    "        #merge\n",
    "        if self.concatenate:\n",
    "            x = Cat(connect_layer,x)\n",
    "        elif self.add:\n",
    "            x = Add(connect_layer,x)\n",
    "        \n",
    "        #conv+bn+lrelu\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.norm_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        #conv+bn+lrelu\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.norm_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 chs = [1,16,32,64,128],\n",
    "                 concatenate:bool = False,\n",
    "                 add:bool = False,\n",
    "                 Crop:bool=False,\n",
    "                 pooling = \"max\",\n",
    "                 stride_pooling = True,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 3,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.chs = chs\n",
    "        self.depth = len(chs)-2\n",
    "        self.pooling = pooling\n",
    "        self.stride_pooling = stride_pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        self.concatenate = concatenate\n",
    "        self.add = add\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "        \n",
    "        self.encoder = nn.ModuleList([])\n",
    "        self.decoder = nn.ModuleList([])\n",
    "        for i in range(self.depth):\n",
    "            encoder_layer = DownBlock(\n",
    "                 in_ch=self.chs[i],\n",
    "                 out_ch=self.chs[i+1],\n",
    "                 #concatenate = True,\n",
    "                 stride_pooling = True,\n",
    "                 pooling = self.pooling,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation = self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim= self.dim)\n",
    "            \n",
    "            self.encoder.append(encoder_layer)\n",
    "            \n",
    "            decoder_layer = UpBlock(\n",
    "                 in_ch = self.chs[-1-i],\n",
    "                 out_ch = self.chs[-2-i],\n",
    "                 concatenate= self.concatenate,\n",
    "                 add = self.add,\n",
    "                 Crop=self.Crop,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation= self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim = self.dim,\n",
    "                 up_sample= self.up_sample) \n",
    "            \n",
    "            self.decoder.append(decoder_layer)\n",
    "\n",
    "                       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        connect_list = []\n",
    "        \n",
    "        #encoder path\n",
    "        for i in range(self.depth):\n",
    "            block = self.encoder[i]\n",
    "            x,connect_layer = block(x)\n",
    "            connect_list.append(connect_layer)\n",
    "            \n",
    "        #bottom block\n",
    "        \n",
    "        act_layer = activation_layer(self.activation)\n",
    "        conv_layer1 = conv_layer(self.chs[-2], self.chs[-1], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)          \n",
    "        conv_layer2 = conv_layer(self.chs[-1], self.chs[-1], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        norm_layer = normalization_layer(normalization=self.normalization, num_channels=self.chs[-1],\n",
    "                                           dim=self.dim)  \n",
    "        x = conv_layer1(x)\n",
    "        x = norm_layer(x)\n",
    "        x = act_layer(x)\n",
    "        x = conv_layer2(x)\n",
    "        x = norm_layer(x)\n",
    "        x = act_layer(x)\n",
    "        \n",
    "        #decoder path\n",
    "        for i in range(self.depth):\n",
    "            layer_to_connect = connect_list[-1-i]\n",
    "            block = self.decoder[i]\n",
    "            x = block(x,layer_to_connect)\n",
    "            \n",
    "        #last layer: 16 to 1\n",
    "        conv_layer_final = conv_layer(self.chs[1], self.chs[0], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        norm_layer_final = normalization_layer(normalization=self.normalization, num_channels=self.chs[0],\n",
    "                                           dim=self.dim) \n",
    "        x = conv_layer_final(x)\n",
    "        x = norm_layer_final(x)\n",
    "        x = act_layer(x)\n",
    "            \n",
    "        return x\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(1,1,128,128,32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(chs = [1,16,32,64,128],\n",
    "                 concatenate= False,\n",
    "                 add = True,\n",
    "                 Crop=False,\n",
    "                 pooling = \"max\",\n",
    "                 stride_pooling = True,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation= 'leaky',\n",
    "                 normalization = \"BN\",\n",
    "                 dim= 2,\n",
    "                 up_sample = 'nearest').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"UNet.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"UNet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start to try real image data\n",
    "take one slice of image from xcat.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "P = loadmat('xcat.mat')\n",
    "p = P['data']\n",
    "p1 = p[:,:,256:256+32,3]\n",
    "P1= torch.from_numpy(p1)\n",
    "P1 = P1.unsqueeze(0)\n",
    "P1 = P1.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256, 32])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function torch.randn produces a tensor with elements drawn from a Gaussian distribution of zero mean and unit variance. Multiply by sqrt(0.1) to have the desired variance.\n",
    "\n",
    "x = torch.zeros(5, 10, 20, dtype=torch.float64)\n",
    "x = x + (0.1**0.5)*torch.randn(5, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = P1[:,:,:,0]\n",
    "poisson_noise = torch.poisson(P1)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = P1+poisson_noise\n",
    "label = P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 32])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    x_train, y_train = Variable(image), Variable(label)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()           \n",
    "\n",
    "        y_train = y_train.cuda()\n",
    "            \n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    output = model(x_train) #give us prediction\n",
    "        #print(outputs.shape)\n",
    "        #outputs = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    loss = criterion(output,y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    #train_loss += loss.cpu().data*image.size(0)\n",
    "    train_loss += loss.item()\n",
    "        \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    \n",
    "        #_,predicted = torch.max(outputs.data,1)\n",
    "        \n",
    "        #train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "   # train_accuracy = train_accuracy / len(train)\n",
    "   # train_loss = train_loss / len(train)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.326181\n",
      "Epoch: 1 \tTraining Loss: 0.676394\n",
      "Epoch: 2 \tTraining Loss: 0.540201\n",
      "Epoch: 3 \tTraining Loss: 0.397204\n",
      "Epoch: 4 \tTraining Loss: 0.568383\n",
      "Epoch: 5 \tTraining Loss: 0.512189\n",
      "Epoch: 6 \tTraining Loss: 0.640781\n",
      "Epoch: 7 \tTraining Loss: 0.367809\n",
      "Epoch: 8 \tTraining Loss: 0.497930\n",
      "Epoch: 9 \tTraining Loss: 0.431445\n",
      "Epoch: 10 \tTraining Loss: 0.375984\n",
      "Epoch: 11 \tTraining Loss: 0.596260\n",
      "Epoch: 12 \tTraining Loss: 0.603689\n",
      "Epoch: 13 \tTraining Loss: 0.490472\n",
      "Epoch: 14 \tTraining Loss: 0.499387\n",
      "Epoch: 15 \tTraining Loss: 0.476976\n",
      "Epoch: 16 \tTraining Loss: 0.388960\n",
      "Epoch: 17 \tTraining Loss: 0.385598\n",
      "Epoch: 18 \tTraining Loss: 0.571706\n",
      "Epoch: 19 \tTraining Loss: 0.535650\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "train_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training error and test error plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
