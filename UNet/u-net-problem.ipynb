{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_layer(activation:str):\n",
    "\n",
    "    if activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_layer(normalization: str,\n",
    "                      num_channels: int, dim:int):\n",
    "    if dim == 2:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif dim == 3:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm3d(num_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer(pooling:str, dim:int):\n",
    "    if dim == 2:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        #if pooling == 'stride':\n",
    "           # return nn.Conv2d()\n",
    "    if dim == 3:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool3d(kernel_size=2,stride=2,padding=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_chs, out_chs, kernel_size, stride, padding, dim):\n",
    "    if dim == 2:\n",
    "        return nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\n",
    "    elif dim == 3:\n",
    "        return nn.Conv3d(in_chs, out_chs, kernel_size, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample_layer(up_sample,in_chs = None, out_chs = None, kernel_size = 2, stride = 2, dim = 3):\n",
    "    if up_sample == 'transposed':\n",
    "        if dim == 2:\n",
    "            return nn.ConvTranspose2d(in_chs, out_chs, kernel_size,stride)\n",
    "        elif dim == 3:\n",
    "            return nn.ConvTranspose3d(in_chs, out_chs, kernel_size,stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2, mode=up_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cat(tensor1, tensor2):\n",
    "    \n",
    "    x = torch.cat((tensor1, tensor2), 1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add (tensor1, tensor2):\n",
    "    \n",
    "    x = torch.add(tensor1, tensor2)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock1(nn.Module):\n",
    "    \"\"\"\n",
    "    left part of the U shape.\n",
    "    the repeated application of two 3 × 3 × 3 3D convolution layers, \n",
    "    each followed by a batch normalization (BN) and a leaky rectified\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 chs=[1,16,32,64,128],               \n",
    "                 pooling: str = \"max\",\n",
    "                 kernel_size: int = 3,\n",
    "                 stride:int = 1,\n",
    "                 padding: int = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = 'BN',\n",
    "                 dim: int = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.chs = chs\n",
    "        #self.out_channels = chs[::-1]\n",
    "        self.pooling = pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "        #self.normalization_layer = normalization_layer(normalization=self.normalization, num_channels=out_chs,\n",
    "                                           #dim=self.dim)       \n",
    "        self.pool = pooling_layer(pooling = self.pooling, dim=self.dim)\n",
    "        \n",
    "        #self.tensor_to_cat = nn.ModuleList()\n",
    "        \n",
    "        self.num_level = len(self.chs)-1\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        \n",
    "        for i in range(self.num_level-1):\n",
    "            \n",
    "            in_chs = self.chs[i]\n",
    "            out_chs = self.chs[i+1]\n",
    "            norm_layer = normalization_layer(normalization=self.normalization, num_channels=out_chs,\n",
    "                                           dim=self.dim)\n",
    "            conv_layer1 = conv_layer(in_chs, out_chs, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "            conv_layer2 = conv_layer(out_chs, out_chs, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        \n",
    "            x = conv_layer1(x)\n",
    "            x = norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "\n",
    "            x = conv_layer2(x)\n",
    "            x = norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "\n",
    "            \n",
    "            #x = self.pool(y)\n",
    "            #self.tensor_to_cat.append(x)\n",
    "            stride_layer = conv_layer(self.chs[i+1], self.chs[i+1], kernel_size = self.kernel_size, stride = 2, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "            x = stride_layer(x)\n",
    "\n",
    "            x = norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "            #print(x.shape)\n",
    "\n",
    "\n",
    "        #last level\n",
    "        conv_layer_end1 = conv_layer(self.chs[-2], self.chs[-1], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        conv_layer_end2 = conv_layer(self.chs[-1], self.chs[-1], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        norm_layer_end = normalization_layer(normalization=self.normalization, num_channels=self.chs[-1],\n",
    "                                           dim=self.dim)\n",
    "        x = conv_layer_end1(x)\n",
    "        x = norm_layer_end(x)\n",
    "        x = self.activation_layer(x)\n",
    " \n",
    "        x = conv_layer_end2(x)\n",
    "        x = norm_layer_end(x)\n",
    "        x = self.activation_layer(x)\n",
    "            \n",
    "        \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = list(model.parameters())\n",
    "for num,para in enumerate(paras):\n",
    "    print('number:',num)\n",
    "    print(para)\n",
    "    print('_____________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-1.3660e-03,  1.3096e-01,  1.2187e+00, -2.1254e-02],\n",
       "           [-2.7243e-02,  2.5002e-01,  6.8810e-01,  6.5612e-01],\n",
       "           [-6.4995e-03,  9.8996e-01,  3.9638e-01,  3.0948e-01],\n",
       "           ...,\n",
       "           [ 3.5684e-01,  6.9186e-01,  6.5880e-01,  8.1883e-01],\n",
       "           [ 4.8672e-01,  6.7564e-01,  3.2251e-02,  3.6761e-01],\n",
       "           [ 5.3180e-01,  6.2143e-01,  7.1048e-01,  2.3860e-01]],\n",
       "\n",
       "          [[-6.4301e-02,  8.1877e-01,  3.3855e-01,  3.6440e-01],\n",
       "           [ 9.1067e-01, -3.9725e-02,  1.0892e-01, -2.9553e-03],\n",
       "           [-9.6898e-02,  9.0274e-01, -3.4818e-02, -1.4273e-02],\n",
       "           ...,\n",
       "           [-4.4403e-02,  2.1027e+00, -3.3676e-03,  1.5247e-01],\n",
       "           [-5.0209e-02,  2.3212e+00, -8.0926e-02, -2.1190e-02],\n",
       "           [ 3.3808e-01, -4.7242e-02, -1.9040e-03, -4.4178e-03]],\n",
       "\n",
       "          [[-4.4923e-02, -1.7795e-02, -1.3895e-01, -7.5760e-02],\n",
       "           [-6.0071e-02,  7.1465e-01,  1.4050e+00,  8.9919e-01],\n",
       "           [ 1.4053e-02, -1.3159e-01,  9.9878e-01, -5.8335e-02],\n",
       "           ...,\n",
       "           [-2.5968e-02, -7.1145e-02, -5.6742e-02,  9.2402e-02],\n",
       "           [-8.6508e-02, -3.9652e-02, -8.6587e-02, -5.8750e-03],\n",
       "           [-4.5591e-02,  7.2080e-01, -5.6739e-02,  2.1669e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-6.0526e-02,  7.2944e-01, -6.8521e-02, -7.5871e-02],\n",
       "           [-3.6466e-02,  1.0324e+00, -1.6147e-01, -6.0183e-02],\n",
       "           [-5.5822e-02,  7.9525e-01, -1.3630e-01,  1.0130e+00],\n",
       "           ...,\n",
       "           [-9.6228e-02, -1.1389e-01, -1.0952e-01, -1.8449e-01],\n",
       "           [-1.6355e-01, -1.1278e-01,  8.9257e-01,  6.2633e-01],\n",
       "           [-1.4012e-02,  9.8114e-01,  1.8757e+00,  6.8207e-01]],\n",
       "\n",
       "          [[ 3.3305e-01,  1.2333e+00, -5.7227e-02,  4.5766e-01],\n",
       "           [-1.9590e-01,  1.9654e+00, -1.1966e-01, -2.7069e-02],\n",
       "           [-1.8389e-01,  1.0055e+00, -2.1171e-01,  5.3342e-01],\n",
       "           ...,\n",
       "           [-1.0673e-01, -1.0732e-01, -2.4508e-01,  1.9909e+00],\n",
       "           [ 5.7494e-01, -3.1583e-02,  1.4131e+00,  1.8074e+00],\n",
       "           [-8.3734e-02, -1.3753e-01,  1.0423e+00,  1.4800e-01]],\n",
       "\n",
       "          [[-1.6192e-02,  1.8479e-01, -6.2119e-02, -3.4759e-02],\n",
       "           [-7.5192e-03,  1.1998e-01,  4.1698e-01, -1.3210e-01],\n",
       "           [-1.2293e-01,  1.1668e-02, -8.7053e-02, -8.3117e-02],\n",
       "           ...,\n",
       "           [-3.0314e-03,  4.4049e-02,  1.4674e-01, -7.1294e-02],\n",
       "           [ 2.1744e-01, -1.9135e-02, -1.1849e-02, -1.9445e-01],\n",
       "           [ 1.8509e-02, -4.2141e-02, -2.5976e-02, -2.6878e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 3.6355e-01,  6.5531e-01, -1.2688e-02,  4.9093e-01],\n",
       "           [ 2.2885e-01,  1.1877e+00, -2.7627e-02,  9.7456e-01],\n",
       "           [ 4.2030e-01, -6.5147e-02, -1.1836e-02,  5.6246e-01],\n",
       "           ...,\n",
       "           [ 4.8631e-01, -2.1685e-02, -6.1814e-02, -2.0459e-02],\n",
       "           [ 2.8422e-01, -1.0055e-02,  5.0196e-02, -2.0963e-02],\n",
       "           [ 1.3483e-02,  4.1353e-01,  2.1149e-01, -1.7081e-02]],\n",
       "\n",
       "          [[ 8.2126e-01, -2.3204e-03, -8.4964e-02, -3.0679e-02],\n",
       "           [ 7.4168e-01,  5.0862e-01,  2.1811e+00,  1.0757e+00],\n",
       "           [ 3.4023e-01, -5.4005e-02, -8.4508e-02, -5.5675e-02],\n",
       "           ...,\n",
       "           [-4.7805e-02, -1.5744e-01,  3.1267e-01, -9.8094e-02],\n",
       "           [ 5.5386e-01,  5.4721e-01, -1.2855e-03,  1.2478e+00],\n",
       "           [ 8.5948e-02, -6.1727e-02, -5.4748e-02,  4.4400e-01]],\n",
       "\n",
       "          [[ 1.0909e+00,  6.7953e-01,  1.0554e+00,  6.7999e-01],\n",
       "           [ 5.6477e-01,  7.0929e-01,  7.2831e-01, -3.7604e-02],\n",
       "           [-2.2305e-02,  2.8453e-01, -1.1221e-01,  2.6011e-01],\n",
       "           ...,\n",
       "           [ 1.2328e+00, -1.0773e-01, -1.7074e-02, -2.8600e-02],\n",
       "           [ 9.1825e-01, -1.4060e-01, -1.0052e-01, -5.7917e-02],\n",
       "           [ 1.6899e-01, -4.7589e-02, -1.5390e-01,  8.3445e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 8.5135e-01, -3.0215e-02,  1.4777e+00,  2.5537e-01],\n",
       "           [-1.9607e-02, -4.8087e-02, -3.3861e-02, -1.4003e-02],\n",
       "           [ 5.5182e-01, -7.2847e-02,  1.4551e+00, -5.1653e-02],\n",
       "           ...,\n",
       "           [ 2.2827e-01,  1.0268e+00, -1.8933e-01, -2.6453e-02],\n",
       "           [ 9.4815e-01, -1.8946e-01,  5.7883e-01,  1.1992e+00],\n",
       "           [ 1.3405e+00, -2.3100e-02,  9.5600e-01, -2.3631e-02]],\n",
       "\n",
       "          [[ 1.0260e+00, -8.3654e-02,  5.2556e-01, -9.5725e-03],\n",
       "           [ 1.3443e+00,  7.1770e-01,  3.0605e-01,  6.6184e-01],\n",
       "           [ 6.7310e-01, -1.1088e-02, -9.2846e-02, -4.6896e-02],\n",
       "           ...,\n",
       "           [ 2.9600e+00,  4.9267e-01,  5.7509e-01, -2.1607e-01],\n",
       "           [ 2.8327e-01, -7.6053e-02,  8.4107e-01, -7.2373e-04],\n",
       "           [ 1.0359e-01,  5.6844e-01, -2.1897e-02, -4.1763e-02]],\n",
       "\n",
       "          [[ 1.9399e-01, -4.7374e-02,  8.0522e-01, -5.9026e-02],\n",
       "           [ 2.8813e-01,  5.1085e-01,  1.5817e+00,  6.4448e-01],\n",
       "           [-2.4573e-02,  1.2389e+00,  1.6532e+00,  1.8472e-02],\n",
       "           ...,\n",
       "           [ 1.7654e+00,  1.3150e+00,  1.8248e+00,  7.2489e-02],\n",
       "           [ 3.9380e-01,  6.9981e-01,  1.2907e+00, -1.2759e-01],\n",
       "           [ 7.1006e-01,  2.4706e-01, -9.5803e-03, -2.9804e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 2.2094e-01, -1.0480e-02, -9.8149e-02, -6.4840e-02],\n",
       "           [ 9.0667e-01,  9.1194e-01, -1.1097e-01,  1.0162e-01],\n",
       "           [ 9.3422e-01,  2.8704e-01,  9.2721e-01, -2.8952e-02],\n",
       "           ...,\n",
       "           [ 7.5139e-01,  6.1844e-01,  3.4125e-01, -2.9063e-02],\n",
       "           [-1.9941e-02,  1.6104e+00, -3.4924e-02, -7.9542e-02],\n",
       "           [-5.1294e-02,  1.0904e-01,  7.4873e-01, -8.1157e-02]],\n",
       "\n",
       "          [[-1.2156e-01, -3.2346e-02, -1.5269e-01, -5.2659e-02],\n",
       "           [-4.2816e-02,  2.8064e-01, -1.7625e-01, -8.3359e-03],\n",
       "           [ 6.7790e-01,  5.1517e-01, -1.3048e-02, -2.4358e-02],\n",
       "           ...,\n",
       "           [-7.5345e-02,  5.7593e-02, -1.8482e-02,  4.8790e-01],\n",
       "           [-8.6084e-02,  1.0781e+00,  1.8388e+00,  1.5110e-01],\n",
       "           [ 2.5359e-01,  2.6031e-01,  7.5775e-01,  7.5676e-02]],\n",
       "\n",
       "          [[-1.3051e-01, -9.2018e-02, -1.0668e-01, -8.4489e-02],\n",
       "           [-1.1591e-02, -8.5922e-02,  3.9093e-01, -9.0318e-02],\n",
       "           [ 4.0350e-01,  7.8934e-01,  1.7712e+00, -1.1496e-01],\n",
       "           ...,\n",
       "           [ 1.5088e+00,  7.0952e-01,  5.8562e-01,  8.8353e-01],\n",
       "           [ 9.7843e-01,  9.2706e-02, -7.7805e-02,  2.9363e-01],\n",
       "           [-1.3097e-02,  8.2991e-01,  6.2830e-01,  4.2338e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-1.8130e-02, -6.6511e-02, -5.3380e-02,  1.9804e-02],\n",
       "           [-4.6918e-02,  1.1677e-01, -7.1526e-02, -1.8263e-01],\n",
       "           [-2.5488e-02,  1.6470e+00,  7.8994e-01,  1.8207e-01],\n",
       "           ...,\n",
       "           [ 4.2541e-01, -1.5442e-01, -8.2537e-02, -7.3097e-02],\n",
       "           [ 1.7624e+00,  7.9196e-01, -1.0947e-01,  3.7702e-01],\n",
       "           [ 1.1593e-01,  1.3073e+00, -3.5717e-02,  1.6503e-01]],\n",
       "\n",
       "          [[-8.9150e-02, -9.9304e-02, -1.3659e-01,  9.1615e-02],\n",
       "           [-1.3307e-01,  4.8215e-01, -1.8480e-01, -6.7226e-02],\n",
       "           [-7.3326e-02,  6.7844e-01,  7.7917e-01,  5.4832e-01],\n",
       "           ...,\n",
       "           [ 3.0665e-02, -1.1930e-01, -9.4286e-02, -5.0722e-02],\n",
       "           [ 3.0461e-01,  4.4643e-01, -5.2601e-02,  5.6044e-01],\n",
       "           [ 4.3544e-01, -3.5097e-02,  1.1502e+00,  2.2308e-01]],\n",
       "\n",
       "          [[ 6.0808e-02,  4.1540e-01, -1.9841e-02, -3.1070e-02],\n",
       "           [-8.0300e-03, -1.3217e-02,  3.1664e-01, -8.0737e-02],\n",
       "           [-5.7123e-02,  2.7577e-01, -4.0142e-02, -7.8267e-02],\n",
       "           ...,\n",
       "           [-1.5854e-02,  7.4944e-01, -1.7362e-01,  6.7434e-01],\n",
       "           [-2.1019e-01, -3.5194e-02,  4.6090e-01, -3.0394e-02],\n",
       "           [-1.1997e-03, -2.4446e-02, -6.5280e-02,  1.5816e-01]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[-1.7364e-02,  8.2670e-01,  5.6598e-01,  2.8466e-01],\n",
       "           [ 9.1744e-01,  5.4864e-01, -1.0060e-02, -2.3796e-02],\n",
       "           [ 1.0498e-01,  6.9060e-01, -6.4509e-02, -1.3235e-02],\n",
       "           ...,\n",
       "           [-4.5380e-02,  1.2659e+00, -3.6747e-02, -4.2003e-02],\n",
       "           [ 6.4017e-02,  5.6050e-01,  4.5331e-01,  9.4549e-02],\n",
       "           [ 8.2617e-01,  5.9840e-01, -2.1725e-02, -1.5227e-02]],\n",
       "\n",
       "          [[-5.5428e-02,  1.5589e+00,  6.6273e-02,  1.2398e+00],\n",
       "           [-5.5900e-02,  6.8612e-01,  6.4817e-01, -2.2377e-03],\n",
       "           [ 3.5025e-02,  1.1928e+00, -1.2754e-01,  8.3012e-01],\n",
       "           ...,\n",
       "           [-3.2203e-02,  7.5151e-01, -3.6270e-02,  1.2039e+00],\n",
       "           [ 6.9559e-02,  1.2400e+00, -5.6473e-02, -1.8337e-02],\n",
       "           [ 3.2774e-02,  1.1973e+00, -9.0930e-02, -4.6878e-02]],\n",
       "\n",
       "          [[ 8.5856e-02,  1.5572e+00, -7.3211e-03,  1.1550e+00],\n",
       "           [-4.7631e-02,  8.0965e-02,  9.3614e-01,  1.9641e-01],\n",
       "           [ 3.7639e-01,  1.5848e+00, -8.9631e-03, -1.1428e-01],\n",
       "           ...,\n",
       "           [-3.1848e-02,  8.9718e-01,  5.6055e-02,  1.1665e+00],\n",
       "           [ 3.0303e-03,  5.4181e-01, -8.2641e-02,  3.4230e-01],\n",
       "           [ 7.4945e-01, -8.2437e-02, -1.2226e-01, -1.1395e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 3.1645e-02,  1.2884e+00, -3.6128e-02, -9.1355e-03],\n",
       "           [ 7.2300e-01,  1.2860e+00,  1.6859e+00, -6.4983e-02],\n",
       "           [ 9.9947e-01, -1.5291e-02, -7.4276e-02, -8.3668e-02],\n",
       "           ...,\n",
       "           [-7.7886e-03,  1.2529e+00,  9.5964e-01,  3.0206e-01],\n",
       "           [ 2.4349e-01,  5.5934e-01,  2.1847e+00,  5.0645e-01],\n",
       "           [ 1.1054e+00, -2.4098e-02, -2.0389e-01, -1.2569e-01]],\n",
       "\n",
       "          [[-1.3966e-02,  5.4583e-01,  1.0688e-01,  5.5952e-01],\n",
       "           [ 3.3437e-01,  8.2236e-01,  1.3337e-01, -8.2734e-02],\n",
       "           [ 4.0437e-01,  1.3950e-01, -1.2854e-01,  8.1600e-01],\n",
       "           ...,\n",
       "           [-7.4066e-02,  1.4431e+00, -3.5192e-01, -2.0477e-01],\n",
       "           [ 4.3503e-01,  9.3239e-01, -1.9328e-01,  2.9645e-01],\n",
       "           [-9.8782e-02, -1.0974e-02, -2.2115e-01, -8.3584e-03]],\n",
       "\n",
       "          [[ 1.1091e+00,  6.1164e-01,  5.6153e-01,  3.5561e-01],\n",
       "           [ 6.8254e-01,  1.4850e+00,  8.6815e-01,  1.9690e+00],\n",
       "           [ 1.2146e-01,  7.7279e-01, -1.2679e-01,  1.0821e-01],\n",
       "           ...,\n",
       "           [ 9.9308e-01,  8.5820e-01, -1.2636e-02, -8.8051e-03],\n",
       "           [ 1.7768e-01,  1.0133e+00,  6.3594e-02, -7.5897e-02],\n",
       "           [ 6.2460e-01, -2.7329e-02, -2.3526e-02,  5.0002e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 5.1564e-01,  4.5358e-01, -1.2306e-02, -1.2617e-03],\n",
       "           [ 4.2118e-01,  6.4485e-01, -1.4018e-01, -1.1872e-01],\n",
       "           [ 8.0204e-01, -2.2652e-03,  5.2939e-01, -9.7086e-02],\n",
       "           ...,\n",
       "           [ 8.3691e-01,  4.9982e-01, -1.3152e-01, -3.1851e-02],\n",
       "           [ 6.9548e-01, -4.8626e-02, -5.5233e-02, -1.1365e-01],\n",
       "           [ 4.2250e-01,  3.2727e-01, -9.3189e-02, -1.0298e-01]],\n",
       "\n",
       "          [[-8.7637e-02, -1.0338e-01, -4.1956e-02, -5.3967e-02],\n",
       "           [-3.3308e-02,  1.7935e+00, -1.8014e-02, -1.2987e-01],\n",
       "           [ 6.4177e-01, -7.8914e-02,  7.5354e-01, -1.8811e-02],\n",
       "           ...,\n",
       "           [ 1.3947e-01,  1.2893e-01, -1.7719e-01, -4.5716e-02],\n",
       "           [-7.0672e-02, -2.3385e-02,  5.2909e-01,  8.0912e-01],\n",
       "           [-6.7659e-02,  2.0848e+00,  1.6839e-01,  1.1617e+00]],\n",
       "\n",
       "          [[ 8.1161e-01,  9.8989e-02, -1.8240e-01, -7.5808e-02],\n",
       "           [ 1.1371e+00,  8.4997e-02, -1.5321e-02, -2.3610e-01],\n",
       "           [-3.0924e-02,  8.9722e-01, -7.2045e-03,  7.4062e-01],\n",
       "           ...,\n",
       "           [ 1.4323e+00, -1.3222e-03,  8.2382e-01,  5.7858e-01],\n",
       "           [-2.3056e-02,  9.8949e-01, -4.1287e-02, -1.7536e-02],\n",
       "           [ 2.5417e-01,  3.2894e-01,  5.0963e-01,  3.9209e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-1.0575e-02,  1.0459e+00,  1.4561e+00, -2.0978e-02],\n",
       "           [ 7.4979e-01,  3.9682e+00, -1.2526e-01, -2.2276e-02],\n",
       "           [ 1.2309e+00,  2.2326e-01,  7.2868e-01, -6.2522e-03],\n",
       "           ...,\n",
       "           [-3.8725e-02, -2.0083e-01, -8.8056e-02, -9.3619e-02],\n",
       "           [ 6.5996e-01,  1.3512e+00,  5.9682e-01, -6.9057e-02],\n",
       "           [-8.6596e-02, -4.7546e-02, -2.6854e-02, -3.0318e-03]],\n",
       "\n",
       "          [[-5.1719e-02, -2.9859e-02, -7.6958e-02, -6.6096e-02],\n",
       "           [ 5.0734e-01,  9.9233e-01,  4.8153e-01,  2.1645e-01],\n",
       "           [ 1.0140e+00,  6.7132e-01, -4.7603e-02,  4.2417e-01],\n",
       "           ...,\n",
       "           [-1.3877e-02, -9.2623e-02, -2.3336e-01, -3.7536e-02],\n",
       "           [-7.2195e-02,  6.6023e-01, -8.4905e-03, -1.9479e-01],\n",
       "           [-4.5533e-03,  2.6906e-02, -1.9497e-01, -7.4713e-02]],\n",
       "\n",
       "          [[ 4.4017e-01, -5.8415e-02, -5.5545e-02, -1.0513e-01],\n",
       "           [-1.2252e-02,  1.3504e-01, -2.4054e-02,  3.2030e-01],\n",
       "           [ 1.4208e+00, -6.6402e-02,  1.2732e+00, -5.3516e-02],\n",
       "           ...,\n",
       "           [ 1.2851e+00, -1.1610e-02, -3.0540e-02,  1.7783e-01],\n",
       "           [-2.9494e-03,  1.4421e+00, -1.9820e-01,  7.5407e-01],\n",
       "           [ 1.9136e-01,  1.0913e+00, -5.5218e-03,  7.5435e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 6.1336e-01,  8.9447e-01,  8.1798e-01,  3.8715e-01],\n",
       "           [ 4.9671e-01,  6.7916e-01,  3.2143e-01,  6.1123e-01],\n",
       "           [ 1.5724e-01,  6.9209e-01, -8.7917e-02, -3.5048e-03],\n",
       "           ...,\n",
       "           [ 1.1800e+00,  1.1121e+00,  2.4797e-01, -1.1765e-02],\n",
       "           [ 1.3057e-01,  1.2815e+00, -8.1843e-02,  2.9331e-01],\n",
       "           [ 4.4007e-01,  4.2268e-01,  9.6833e-02,  3.8150e-01]],\n",
       "\n",
       "          [[ 5.6056e-01,  9.1021e-02,  8.6589e-01,  1.0044e+00],\n",
       "           [-3.0514e-02,  2.3317e-01, -2.0864e-02,  2.6013e-01],\n",
       "           [ 4.5974e-01, -2.1469e-02, -1.1126e-01, -4.0413e-02],\n",
       "           ...,\n",
       "           [ 7.7843e-02, -7.9674e-02, -3.9058e-02, -7.4065e-02],\n",
       "           [-1.7348e-02,  3.1189e-01,  3.4977e-01, -3.7749e-02],\n",
       "           [-4.0510e-02, -6.3716e-02, -1.1413e-01, -1.0684e-01]],\n",
       "\n",
       "          [[ 9.3778e-01,  2.9380e-01,  9.6425e-01, -2.7641e-03],\n",
       "           [ 2.6790e-02, -5.5222e-02,  5.3911e-01, -6.7282e-02],\n",
       "           [ 1.0224e+00,  1.0490e-02,  2.0167e-01, -1.1479e-01],\n",
       "           ...,\n",
       "           [-4.0291e-02, -1.3288e-01,  2.4064e-01, -9.1623e-02],\n",
       "           [ 3.4022e-01,  4.5564e-01,  3.5416e-02, -1.2528e-01],\n",
       "           [ 2.4116e-02, -1.2244e-01, -1.6180e-01, -3.4325e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.5960e-01,  1.6250e+00,  1.8052e+00,  1.2682e+00],\n",
       "           [ 2.7939e-01,  3.3660e-01,  6.0917e-01,  8.0323e-02],\n",
       "           [ 6.3168e-01,  7.1591e-02,  1.4089e+00,  4.6957e-01],\n",
       "           ...,\n",
       "           [ 1.9783e+00, -7.2315e-02, -1.2753e-01,  1.6010e+00],\n",
       "           [-3.7040e-02,  2.1066e-01, -6.1062e-02, -4.2741e-02],\n",
       "           [-5.9478e-02,  1.8518e-02, -6.4951e-03, -1.7956e-01]],\n",
       "\n",
       "          [[ 8.0952e-01,  8.9043e-01,  8.2265e-01,  3.1642e-01],\n",
       "           [ 1.1422e+00,  8.0669e-01, -4.6118e-02, -7.6281e-02],\n",
       "           [ 1.1782e+00,  1.7024e+00,  1.1439e+00,  4.3775e-01],\n",
       "           ...,\n",
       "           [ 6.2374e-01,  2.4601e+00, -8.2873e-02, -1.8061e-01],\n",
       "           [ 7.3090e-01,  6.1454e-01,  1.1856e-01, -4.8063e-02],\n",
       "           [ 7.5957e-01, -2.8612e-02, -6.4092e-02, -4.7980e-02]],\n",
       "\n",
       "          [[ 6.5226e-01,  1.0648e+00,  7.9567e-01,  3.3203e-01],\n",
       "           [ 1.1537e+00,  9.2275e-01,  8.9525e-01, -5.4731e-03],\n",
       "           [ 1.3804e-01,  1.9454e-01,  1.0404e+00,  7.8754e-01],\n",
       "           ...,\n",
       "           [ 2.0587e-01,  3.1948e-01, -4.9507e-02, -2.4960e-02],\n",
       "           [ 5.9992e-01,  2.1704e+00, -2.8481e-02, -1.3411e-02],\n",
       "           [ 1.8900e-01, -1.7339e-01,  8.7947e-01, -2.8625e-02]]]]],\n",
       "       grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,1,128,128,32)\n",
    "model = DownBlock1(chs=[1,16,32,64,128],\n",
    "                 #concatenate = True,\n",
    "                 pooling = \"max\",\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation = 'leaky',\n",
    "                 normalization = 'BN',\n",
    "                 dim= 3)\n",
    "\n",
    "model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  # 继承torch的module\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()  # 继承__init__功能\n",
    " # 输出层线性输出\n",
    "        self.n_feature = n_feature\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "    def forward(self, x):\n",
    "        # 激励函数（隐藏层的线性值）\n",
    "        for i in range(3):\n",
    "                    # 定义每一层用什么样的样式\n",
    "            self.hidden1 = torch.nn.Linear(self.n_feature, self.n_hidden)  # 隐藏层线性输出\n",
    "            self.hidden2 = torch.nn.Linear(self.n_hidden, self.n_hidden)  # 隐藏层线性输出\n",
    "            self.predict = torch.nn.Linear(self.n_hidden, self.n_output) \n",
    "            x = torch.relu(self.hidden1(x))\n",
    "            x = torch.relu(self.hidden2(x))\n",
    "        x = self.predict(x)  # 输出值\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(2, 5, 3)\n",
    "paras = list(net.parameters())\n",
    "for num,para in enumerate(paras):\n",
    "    print('number:',num)\n",
    "    print(para)\n",
    "    print('_____________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16384x32 and 2x5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-da6fe3348c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-f57c5f0bfc27>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 隐藏层线性输出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 输出值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16384x32 and 2x5)"
     ]
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-36ee4a8a13d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[0;32m     46\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[0;32m     47\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "optim = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(down_level, up_level):\n",
    "    \"\"\"\n",
    "    the input down_level is each level's last tensor on the left (down) side. e.g. [1,1,256,256,64]; up_level is the first\n",
    "    tensor on the right (up) side.\n",
    "    Center-crops the encoder_layer to the size of the decoder_layer,\n",
    "    so can catanate encoder layer to decoder layer\n",
    "    This is only necessary for input sizes != 2**n for 'same' padding and always required for 'valid' padding.\n",
    "    \"\"\"\n",
    "    if down_level.shape[2:] != up_level.shape[2:]:\n",
    "        down_shape = down_level.shape[2:]\n",
    "        up_shape = up_level.shape[2:]\n",
    "#down_shape should bigger than up_shape\n",
    "        if down_level.dim() == 4:  # 2D\n",
    "            down_level = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((down_shape[0] - up_shape[0]) // 2):((down_shape[0] + up_shape[0]) // 2),\n",
    "                            ((down_shape[1] - up_shape[1]) // 2):((down_shape[1] + up_shape[1]) // 2)\n",
    "                            ]\n",
    "        elif down_level.dim() == 5:  # 3D\n",
    "            down_level = down_level[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((down_shape[0] - up_shape[0]) // 2):((down_shape[0] + up_shape[0]) // 2),\n",
    "                            ((down_shape[1] - up_shape[1]) // 2):((down_shape[1] + up_shape[1]) // 2),\n",
    "                            ((down_shape[2] - up_shape[2]) // 2):((down_shape[2] + up_shape[2]) // 2),\n",
    "                            ]\n",
    "    return down_level, up_level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catanate -> add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 chs = [1,16,32,64,128],\n",
    "                 concatenate:bool = False,\n",
    "                 add : bool = False,\n",
    "                 Crop:bool=True,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 3,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.chs = chs[::-1]\n",
    "        self.concatenate = concatenate\n",
    "        self.add = add\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "\n",
    "    \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "        #self.normalization_layer = normalization_layer(normalization=self.normalization, num_channels=out_chs,\n",
    "                                           #dim=self.dim)       \n",
    "        self.up_sample_layer = up_sample_layer(up_sample = self.up_sample)\n",
    "        \n",
    "        \n",
    "        self.num_level = len(self.chs)-1\n",
    "\n",
    "\n",
    "            \n",
    "    def forward(self, tensor_to_cat, x_from_down):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            encoder_layer: Tensor from the encoder pathway\n",
    "            decoder_layer: Tensor from the decoder pathway (to be up'd)\n",
    "        \"\"\"\n",
    "        x = x_from_down\n",
    "        \n",
    "        if self.up_sample != 'transposed':\n",
    "            \n",
    "            for i in range(self.num_level-1):\n",
    "                in_chs = self.chs[i]\n",
    "                out_chs = self.chs[i+1]    \n",
    "                \n",
    "                conv_layer0 = conv_layer(in_chs, in_chs//2, kernel_size = 3, stride = 1, padding = 1, #to half the channels when up sampling\n",
    "                                          dim = self.dim)\n",
    "                \n",
    "                x = self.up_sample_layer(x)  # double the image size\n",
    "                x = conv_layer0(x) #half the channels\n",
    "                \n",
    "                if self.Crop:\n",
    "                    cropped_tensor, up_tensor = crop(tensor_to_cat[i], x)  # cropping\n",
    "                    if self.cat:\n",
    "                        x = Cat(cropped_tensor,up_tensor)\n",
    "                    elif self.add:\n",
    "                        x = Add(cropped_tensor,up_tensor)\n",
    "                    \n",
    "                else:\n",
    "                    if self.cat:\n",
    "                        x = Cat(tensor_to_cat[-i-1],x)\n",
    "                    elif self.add:\n",
    "                        x = Add(tensor_to_cat[-i-1],x)\n",
    "                    \n",
    "            #conv-BN-ACTIVATION\n",
    "                conv_layer1 = conv_layer(in_chs, out_chs, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "                conv_layer2 = conv_layer(out_chs, out_chs, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "                norm_layer = normalization_layer(normalization=self.normalization, num_channels=out_chs,\n",
    "                                           dim=self.dim)\n",
    "                x = conv_layer1(x)\n",
    "                x = norm_layer(x)\n",
    "                x = self.activation_layer(x)\n",
    "                x = conv_layer2(x)\n",
    "                x = norm_layer(x)\n",
    "                x = self.activation_layer(x)\n",
    "                \n",
    "            conv_layer_end = conv_layer(self.chs[-2], self.chs[-1], kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "            x = conv_layer_end(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = UpBlock(chs = [1,16,32,64,128],\n",
    "                 concatenate= True,\n",
    "                 Crop=False,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation= 'leaky',\n",
    "                 normalization = \"BN\",\n",
    "                 dim = 3,\n",
    "                 up_sample= 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=model1(ts,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 chs = [1,16,32,64,128],\n",
    "                 concatenate:bool = False,\n",
    "                 add:bool = False,\n",
    "                 Crop:bool=True,\n",
    "                 pooling = \"max\",\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 3,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.chs = chs\n",
    "\n",
    "        self.pooling = pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        #self.chs = chs[::-1]\n",
    "        self.concatenate = concatenate\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "        \n",
    "        self.UpBlock = UpBlock(chs = self.chs,\n",
    "                 concatenate= self.concatenate,\n",
    "                 Crop=self.Crop,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation= self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim = self.dim,\n",
    "                 up_sample= self.up_sample)\n",
    "        \n",
    "        self.DownBlock = DownBlock(chs=self.chs,\n",
    "                 pooling = self.pooling,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation = self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim= self.dim)    \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_from_down, tensor_to_cat = self.DownBlock(x)\n",
    "        x = self.UpBlock(tensor_to_cat,x_from_down)\n",
    "            \n",
    "        return x\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(1,1,128,128,32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(chs = [1,16,32,64,128],\n",
    "                 concatenate= True,\n",
    "                 Crop=False,\n",
    "                 pooling = \"max\",\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation= 'leaky',\n",
    "                 normalization = \"BN\",\n",
    "                 dim= 3,\n",
    "                 up_sample = 'nearest').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = unet(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start to try real image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = loadmat('xcat.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = P['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p[:,:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p[:,:,256:256+32,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1= torch.from_numpy(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = P1.unsqueeze(0)\n",
    "P1 = P1.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = unet(P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= z[0,0,:,:,0]\n",
    "output = output.detach().numpy()\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function torch.randn produces a tensor with elements drawn from a Gaussian distribution of zero mean and unit variance. Multiply by sqrt(0.1) to have the desired variance.\n",
    "\n",
    "x = torch.zeros(5, 10, 20, dtype=torch.float64)\n",
    "x = x + (0.1**0.5)*torch.randn(5, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = P1[0,0,:,:,0]\n",
    "poisson_noise = torch.poisson(P1)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = P1+poisson_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = list(unet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "if torch.cuda.is_available():\n",
    "    unet = unet.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    unet.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "            #images = Variable(images.cuda())            \n",
    "        input1 = input1.to(device)\n",
    "            #labels = Variable(labels.cuda())\n",
    "            \n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    output = unet(input1) #give us prediction\n",
    "        #print(outputs.shape)\n",
    "        #outputs = torch.argmax(outputs, dim=1)\n",
    "    label = P1\n",
    "    loss = criterion(label,output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    train_loss += loss.cpu().data*input1.size(0)\n",
    "        \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    \n",
    "        #_,predicted = torch.max(outputs.data,1)\n",
    "        \n",
    "        #train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "   # train_accuracy = train_accuracy / len(train)\n",
    "   # train_loss = train_loss / len(train)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "train_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training error and test error plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
