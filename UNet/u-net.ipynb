{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from scipy.io import loadmat\n",
    "import pathlib\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from skimage.measure import compare_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_layer(activation:str):\n",
    "\n",
    "    if activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_layer(normalization: str,\n",
    "                      num_channels: int, dim:int):\n",
    "    if dim == 2:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif dim == 3:\n",
    "        if normalization == 'BN':\n",
    "            return nn.BatchNorm3d(num_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer(pooling:str, dim:int):\n",
    "    if dim == 2:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        elif pooling == 'avg':\n",
    "            return nn.AvgPool2d(kernel_size=2,stride=2,padding=0)\n",
    "\n",
    "    if dim == 3:\n",
    "        if pooling == \"max\":\n",
    "            return nn.MaxPool3d(kernel_size=2,stride=2,padding=0)\n",
    "        elif pooling == 'avg':\n",
    "            return nn.AvgPool3d(kernel_size=2,stride=2,padding=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_chs, out_chs, kernel_size, stride, padding, dim):\n",
    "    if dim == 2:\n",
    "        return nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\n",
    "    elif dim == 3:\n",
    "        return nn.Conv3d(in_chs, out_chs, kernel_size, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample_layer(up_sample,in_chs = None, out_chs = None, kernel_size = 2, stride = 2, dim = 3):\n",
    "    if up_sample == 'transposed':\n",
    "        if dim == 2:\n",
    "            return nn.ConvTranspose2d(in_chs, out_chs, kernel_size,stride)\n",
    "        elif dim == 3:\n",
    "            return nn.ConvTranspose3d(in_chs, out_chs, kernel_size,stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2, mode=up_sample) # mode can be 'nearest', 'bilinear' ,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cat(tensor1, tensor2):\n",
    "    \n",
    "    x = torch.cat((tensor1, tensor2), 1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add (tensor1, tensor2):\n",
    "    \n",
    "    x = torch.add(tensor1, tensor2)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    represent a block from the left part of  U shape.\n",
    "    it contains two convolution layers, \n",
    "    each followed by a batch normalization (BN) and a leaky rectified,\n",
    "    and a downsampling layer followed by a BN and leakyRElu\n",
    "      \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 stride_pooling:bool,\n",
    "                 pooling: str = \"max\",     \n",
    "                 kernel_size: int = 3,\n",
    "                 stride:int = 1,\n",
    "                 padding: int = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = 'BN',\n",
    "                 dim: int = 2\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.pooling = pooling\n",
    "        self.stride_pooling = stride_pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "        self.normalization_layer = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim)       \n",
    "        self.pooling_layer = pooling_layer(pooling = self.pooling, dim=self.dim)\n",
    "        self.stride_layer = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = 2, padding = self.padding, \n",
    "                                          dim = self.dim)      \n",
    "        self.conv_layer1 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        self.conv_layer2 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        connect_layer = x\n",
    "        if self.stride_pooling:\n",
    "            x = self.stride_layer(x)            \n",
    "        else:\n",
    "            x =  self.pooling_layer(x)\n",
    "        x = self.normalization_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "                                                       \n",
    "        return x,connect_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent(nn.Module):\n",
    "    \"\"\"\n",
    "    Latent, also called bottleneck, represents the bottom middle part of the UNet.\n",
    "    In this work, it contains a conv+BN+LeakyRelu + conv+BN+LeakyRelu.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 2\n",
    "\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_ch =in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "        self.norm_layer = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim) \n",
    "        self.conv_layer1 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)          \n",
    "        self.conv_layer2 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "    def forward(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.norm_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.norm_layer(x)\n",
    "        x = self.activation_layer(x)\n",
    "        \n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    it corresponds to \"red arrow+blue arrow+ blue arrow\", i.e.\n",
    "    [decon_layer (half the number of channels)+ Upsampling (double image size)]+\n",
    "    [conv+bn+leaky]+[con+bn+leaky]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 concatenate:bool = False,\n",
    "                 add : bool = False,\n",
    "                 Crop:bool = False,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 2,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_ch =in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.concatenate = concatenate\n",
    "        self.add = add\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "\n",
    "    \n",
    "        self.activation_layer = activation_layer(self.activation)\n",
    "     \n",
    "        self.up_sample_layer = up_sample_layer(up_sample = self.up_sample)\n",
    "        \n",
    "        self.conv_layer1 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        if self.add:\n",
    "            self.conv_layer2 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        elif self.concatenate:\n",
    "            self.conv_layer2 = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "            self.conv_layer3 = conv_layer(self.out_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        self.norm_layer = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim)        \n",
    "            \n",
    "    def forward(self, x, connect_layer):\n",
    "\n",
    "        #deconv + upsample\n",
    "        x = self.conv_layer1(x) #128 -> 64\n",
    "        x = self.up_sample_layer(x) # 32*32 -> 64*64\n",
    "        \n",
    "        #merge\n",
    "        if self.concatenate:\n",
    "            x = Cat(connect_layer,x) #64 -> 128\n",
    "            x = self.conv_layer2(x) #128->64\n",
    "            x = self.norm_layer(x) \n",
    "            x = self.activation_layer(x)\n",
    "            x = self.conv_layer3(x) #64 -> 64\n",
    "            x = self.norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "            \n",
    "        elif self.add:\n",
    "            x = Add(connect_layer,x)\n",
    "        \n",
    "            #conv+bn+lrelu\n",
    "            x = self.conv_layer2(x)\n",
    "            x = self.norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "            #conv+bn+lrelu\n",
    "            x = self.conv_layer2(x)\n",
    "            x = self.norm_layer(x)\n",
    "            x = self.activation_layer(x)\n",
    "        \n",
    "        \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class last_block(nn.Module):\n",
    "    \"\"\"\n",
    "    it's the last block of layers after the UpBlock to make channel 16 into channel 1.\n",
    "    it contains conv+bn+leakyRelu\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_ch,\n",
    "                 out_ch,\n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 2\n",
    "\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.conv_layer_final = conv_layer(self.in_ch, self.out_ch, kernel_size = self.kernel_size, stride = self.stride, padding = self.padding, \n",
    "                                          dim = self.dim)\n",
    "        self.norm_layer_final = normalization_layer(normalization=self.normalization, num_channels=self.out_ch,\n",
    "                                           dim=self.dim) \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv_layer_final(x)\n",
    "        x = self.norm_layer_final(x)\n",
    "        #x = act_layer(x)\n",
    "        #x = nn.Sigmoid()(x)\n",
    "        #x = nn.Linear(256,256)(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    it combines DownBlock + middle bottom of U shape + UpBlock + the final conv_layer.\n",
    "    we want to follow the UNet from the paper, so  here depth is 3, which means\n",
    "    the UNet will first run DownBlock for three times,\n",
    "    then reach the bottom, and will run \"conv+bn+leaky\" +\"conv+bn+leaky\",\n",
    "    then will run UpBlock for three times,\n",
    "    then we add the last layer to make channels from 16 -> 1\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 stride_pooling:bool,\n",
    "                 chs = [1,16,32,64,128],\n",
    "                 concatenate:bool = False,\n",
    "                 add:bool = False,\n",
    "                 Crop:bool=False,\n",
    "                 pooling = \"max\",\n",
    "                 \n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation: str = 'leaky',\n",
    "                 normalization: str = \"BN\",\n",
    "                 dim: int = 3,\n",
    "                 up_sample: str = 'nearest'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.chs = chs\n",
    "        self.depth = len(chs)-2\n",
    "        self.pooling = pooling\n",
    "        self.stride_pooling = stride_pooling\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.dim = dim\n",
    "        self.concatenate = concatenate\n",
    "        self.add = add\n",
    "        self.up_sample = up_sample\n",
    "        self.Crop = Crop\n",
    "        \n",
    "        \n",
    "        self.encoder = nn.ModuleList([])\n",
    "        self.decoder = nn.ModuleList([])\n",
    "        self.latent = Latent(in_ch = self.chs[-2],\n",
    "                             out_ch = self.chs[-1],\n",
    "                             kernel_size = self.kernel_size,\n",
    "                             stride = self.stride,\n",
    "                             padding = self.padding,\n",
    "                             activation = self.activation,\n",
    "                             normalization = self.normalization,\n",
    "                             dim = self.dim)\n",
    "        self.last_block = last_block(in_ch = self.chs[1],\n",
    "                             out_ch = self.chs[0],\n",
    "                             kernel_size = self.kernel_size,\n",
    "                             stride = self.stride,\n",
    "                             padding = self.padding,\n",
    "                             activation = self.activation,\n",
    "                             normalization = self.normalization,\n",
    "                             dim = self.dim)\n",
    "        \n",
    "        for i in range(self.depth):\n",
    "            encoder_layer = DownBlock(\n",
    "                 in_ch=self.chs[i],\n",
    "                 out_ch=self.chs[i+1],\n",
    "                 #concatenate = True,\n",
    "                 stride_pooling = self.stride_pooling,\n",
    "                 pooling = self.pooling,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation = self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim= self.dim)\n",
    "            \n",
    "            self.encoder.append(encoder_layer) #encoder is the modulelist, and it appends each downblocks\n",
    "            \n",
    "            decoder_layer = UpBlock(\n",
    "                 in_ch = self.chs[-1-i],\n",
    "                 out_ch = self.chs[-2-i],\n",
    "                 concatenate= self.concatenate,\n",
    "                 add = self.add,\n",
    "                 Crop=self.Crop,\n",
    "                 kernel_size = self.kernel_size,\n",
    "                 stride = self.stride,\n",
    "                 padding = self.padding,\n",
    "                 activation= self.activation,\n",
    "                 normalization = self.normalization,\n",
    "                 dim = self.dim,\n",
    "                 up_sample= self.up_sample) \n",
    "            \n",
    "            self.decoder.append(decoder_layer)\n",
    "            \n",
    "        self.set_weights()\n",
    "        \n",
    "\n",
    "    @staticmethod        \n",
    "    def weight_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            #nn.init.xavier_normal(m.weight)\n",
    "            nn.init.constant(m.bias, 0)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('Sigmoid') != -1:\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "        #elif classname.find('Leaky') != -1:\n",
    "            #nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        elif classname.find('Linear') != -1:\n",
    "            nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            \n",
    "   \n",
    "    def set_weights(self):\n",
    "        for i,m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "            \n",
    "        \n",
    "    def forward(self,x):\n",
    "        connect_list = [] #it contains the layer from encoder path which need to skip to connect\n",
    "        \n",
    "        #encoder path\n",
    "        for i in range(self.depth):\n",
    "            block = self.encoder[i]\n",
    "            x,connect_layer = block(x)\n",
    "            connect_list.append(connect_layer)\n",
    "            \n",
    "        #bottom block: the middle and bottom part of UNet\n",
    "        \n",
    "        x = self.latent(x)\n",
    "        \n",
    "        #decoder path\n",
    "        for i in range(self.depth):\n",
    "            layer_to_connect = connect_list[-1-i]\n",
    "            block = self.decoder[i]\n",
    "            x = block(x,layer_to_connect)\n",
    "            \n",
    "        #last layer : 16 to 1\n",
    "        x = self.last_block(x)\n",
    "        \n",
    "        \n",
    "            \n",
    "        return x\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload image and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image_not_normalize(file_name):\n",
    "    \"\"\"\n",
    "    This function uploads the data.\n",
    "    input:\n",
    "        file_name is a str, e.g. 'xcat.mat'\n",
    "    returns:\n",
    "        Pmean: the mean of temporal frames. Shape(1,1,256,256,400)\n",
    "        blurry_P : each temporal frames has been added Gaussian noise with sigma = 5. Shape(1,1,256,256,400,14)\n",
    "        Pgt :ground-truth / original image. Shape(1,1,256,256,400,14)\n",
    "    \"\"\"\n",
    "    P = loadmat(file_name)\n",
    "    p = P['data']\n",
    "\n",
    "    P1= torch.from_numpy(p)\n",
    "    P14 = P1#P14 has 14 temporal frames\n",
    "    Pgt = P14.unsqueeze(0)\n",
    "    Pgt = Pgt.unsqueeze(0)# shape (1,1,256,256,400,14)\n",
    "    \n",
    "    #mean temporal frame\n",
    "    P1 = torch.mean(P1,dim=3) \n",
    "    P = P1.unsqueeze(0)\n",
    "    Pmean = P.unsqueeze(0) #shape will be (1,1,256,256,400)\n",
    "\n",
    "    #each temporal frame+gaussian noise\n",
    "    g_noise = torch.normal(0,5,(256,256,400,14)) #create a gaussian with mean 0, sigma 5\n",
    "    noisyP=P14\n",
    "    noisyP=noisyP + g_noise   \n",
    "    blurry_P = noisyP.unsqueeze(0)\n",
    "    blurry_P = blurry_P.unsqueeze(0)# shape (1,1,256,256,400,14)\n",
    "    \n",
    "    \n",
    "    return Pmean,blurry_P,Pgt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image(file_name):\n",
    "    \"\"\"\n",
    "    This function uploads and normalize the data.\n",
    "    input:\n",
    "        file_name is a str, e.g. 'xcat.mat'\n",
    "    returns:\n",
    "        Pmean: the mean of temporal frames. Shape(1,1,256,256,400)\n",
    "        blurry_P : each temporal frames has been added Gaussian noise with sigma = 5. Shape(1,1,256,256,400,14)\n",
    "        Pgt :ground-truth / original image. Shape(1,1,256,256,400,14)\n",
    "    \"\"\"\n",
    "    P = loadmat(file_name)\n",
    "    p = P['data']\n",
    "\n",
    "    P1= torch.from_numpy(p)\n",
    "    P14 = P1#P14 has 14 temporal frames\n",
    "    Pgt = (P14-P14.min())/(P14.max()-P14.min())\n",
    "    Pgt = Pgt.unsqueeze(0)\n",
    "    Pgt = Pgt.unsqueeze(0)# shape (1,1,256,256,400,14)\n",
    "    \n",
    "    #mean temporal frame\n",
    "    P1 = torch.mean(P1,dim=3) \n",
    "    P = (P1-P1.min())/(P1.max()-P1.min()) #scale P1 to (0,1)\n",
    "    P = P.unsqueeze(0)\n",
    "    Pmean = P.unsqueeze(0) #shape will be (1,1,256,256,400)\n",
    "\n",
    "    #each temporal frame+gaussian noise\n",
    "    g_noise = torch.normal(0,5,(256,256,400,14)) #create a gaussian with mean 0, sigma 5\n",
    "    noisyP=P14\n",
    "    noisyP=noisyP + g_noise   \n",
    "    blurry_P = (noisyP-noisyP.min())/(noisyP.max()-noisyP.min()) #normalize the blurry image\n",
    "    blurry_P = blurry_P.unsqueeze(0)\n",
    "    blurry_P = blurry_P.unsqueeze(0)# shape (1,1,256,256,400,14)\n",
    "    \n",
    "    \n",
    "    return Pmean,blurry_P,Pgt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pmean,blurry_P,Pgt = upload_image_not_normalize('xcat.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8c202a5c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Pmean[0,0,:,:,120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the output images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output_img(output_img,epoch,i,folder,train_loss,psnr,cc): # i is for telling which time (from 1 to 14); \n",
    "                                                                   #folder has three types because there are three kids of input_image\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)   \n",
    "    plot = plt.imshow(output_img[0,0,:,:,120])\n",
    "    plt.clim(0,1)#have same color range\n",
    "    plt.title('Dynamic time:{},Epoch: {}, Training Loss: {:.5f}, PSNR: {:.5f},CC:{:.5f}'.format(i+1,epoch+1, train_loss,psnr,cc))\n",
    "\n",
    "    plt.savefig(folder+'output_image{}-{}.png'.format(i+1,epoch+1)) #e.g. output_image1-1000 means the 1000th image at time 1\n",
    "    plt.close(fig)#not display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(optimizer:str = 'Adam'):\n",
    "    if optimizer == 'Adam':\n",
    "        return Adam(model.parameters(), lr=1e-3)\n",
    "    elif optimizer == 'SGD':\n",
    "        return torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(criterion:str = 'MSE'):\n",
    "    if criterion == 'MSE':\n",
    "        return nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(model,criterion_name,optimizer_name,input_image,label_image,epoch,i,folder):\n",
    "    optimizer = optim(optimizer_name)\n",
    "    criterion = loss(criterion_name)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    def train(epoch):\n",
    "    #strat TRAIN mode\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        x_train, label= Variable(input_image), Variable(label_image)\n",
    "    \n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "        \n",
    "            x_train = x_train.cuda()           \n",
    "            label = label.cuda()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train)\n",
    "        output_img = output.detach().numpy()\n",
    "        \n",
    "        loss = criterion(output,label)\n",
    "    #compute gradient\n",
    "        loss.backward()\n",
    "    #update parameters\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1)\n",
    "        optimizer.step()    \n",
    "         \n",
    "    \n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        #correlation coeeficient\n",
    "        cm = np.corrcoef(output_img[0,0,:,:,120].flat,label_image[0,0,:,:,120].numpy().flat)\n",
    "        cc = cm[0,1]\n",
    "        \n",
    "        #psnr\n",
    "        psnr = compare_psnr(label_image.numpy(), output_img,1)        \n",
    "        \n",
    "        loss_list.append(train_loss)\n",
    "        cc_list.append(cc)\n",
    "        psnr_list.append(psnr)\n",
    "        \n",
    "\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tPSNR: {:.6f} \\tCC:{:6f}'.format(epoch, train_loss,psnr,cc))\n",
    "        \n",
    "        \n",
    "        if (epoch+1) %100 == 0:  #this only display the output of tevery 100 iteration\n",
    "            #fig.add_subplot(3,4,(epoch+1)/200)\n",
    "            #plt.imshow(output_img[0,0,:,:])\n",
    "            #plt.clim(0,1)\n",
    "            \n",
    "            save_output_img(output_img,epoch,i,folder,train_loss,psnr,cc)\n",
    "            \n",
    "    \n",
    "    return train(epoch)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    }
   ],
   "source": [
    "unet = UNet(stride_pooling = True,\n",
    "                 chs = [1,16,32,64,128],\n",
    "                 concatenate= False,\n",
    "                 add = True,\n",
    "                 Crop=False,\n",
    "                 pooling = \"max\",\n",
    "                 \n",
    "                 kernel_size = 3,\n",
    "                 stride = 1,\n",
    "                 padding = 1,\n",
    "                 activation= 'leaky',\n",
    "                 normalization = \"BN\",\n",
    "                 dim= 3,\n",
    "                 up_sample= 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(unet, (1,256,256,400), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'xcat.mat'\n",
    "Pmean,blurry_P,Pgt = upload_image_not_normalize(file_name)\n",
    "uniform_noise = torch.randn(1,1,256,256,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet\n",
    "#model = unet\n",
    "criterion_name = 'MSE'\n",
    "optimizer_name = 'Adam'\n",
    "#input_image = p_noise\n",
    "#input_image = P1\n",
    "input_image1 = uniform_noise\n",
    "input_image2 = Pmean\n",
    "input_image3 = blurry_P\n",
    "#label_image = P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pmean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-564cf588c7ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Pmean' is not defined"
     ]
    }
   ],
   "source": [
    "Pmean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a folder for all the output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'xcat.mat'\n",
    "folder1 = file_name[0:3]+'_mean_frame/'\n",
    "folder2 = file_name[0:3]+'_noise/'\n",
    "folder3 = file_name[0:3]+'_blurryImage/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(folder1)\n",
    "os.makedirs(folder2)\n",
    "os.makedirs(folder3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iterate the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train_loss = 0\n",
    "loss_list = []\n",
    "cc_list = []\n",
    "psnr_list = []\n",
    "\n",
    "for i in range(14): #time = 14\n",
    "    label_image = Pgt[0,0,:,:,:,i]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_setup(model,criterion_name,optimizer_name,input_image1,label_image,epoch,i,folder1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(14): #time = 14\n",
    "    label_image = Pgt[0,0,:,:,:,i]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_setup(model,criterion_name,optimizer_name,input_image2,label_image,epoch,i,folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(14): #time = 14\n",
    "    label_image = Pgt[0,0,:,:,:,i]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_setup(model,criterion_name,optimizer_name,input_image3,label_image,epoch,i,folder3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)  \n",
    "plt.plot(loss_list,label='Training loss')\n",
    "plt.title('Training Loss')\n",
    "plt.savefig(folder1+'loss.png')\n",
    "plt.close(fig1)#not display the image\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)  \n",
    "plt.plot(psnr_list,label='PSNR')\n",
    "plt.title('PSNR')\n",
    "plt.savefig(folder2+'PSNR.png')\n",
    "plt.close(fig2)\n",
    "\n",
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(111)  \n",
    "plt.plot(cc_list,label='cc')\n",
    "plt.title('Pearson correlation coefficient')\n",
    "plt.savefig(folder3+'cc.png')\n",
    "plt.close(fig3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
